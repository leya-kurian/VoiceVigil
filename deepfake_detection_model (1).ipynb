{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UrqjyIUvCyD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tensorflow import keras\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Audio\n",
        "import subprocess\n",
        "import random\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O4RJtHEc5-D"
      },
      "source": [
        "Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iG-dfUa0ZVJ",
        "outputId": "2902d8d5-4218-4c9d-a375-fea4ff97718b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpio6zCv-Nqw"
      },
      "outputs": [],
      "source": [
        "!cp -r \"../content/gdrive/MyDrive/deepfake_dataset\" ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zmmrN5-dDW3"
      },
      "source": [
        "Getting data directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHyAwXzBSZ3n"
      },
      "outputs": [],
      "source": [
        "data_directory = \"./deepfake_dataset/AUDIO\"\n",
        "audio_folder = \"audio\"\n",
        "noise_folder = \"noise\"\n",
        "\n",
        "audio_path = os.path.join(data_directory, audio_folder)\n",
        "noise_path = os.path.join(data_directory, noise_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wKjjYN8NSrFK",
        "outputId": "45f2cba8-9b91-4a92-ed20-545681a7aee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./deepfake_dataset/AUDIO/audio'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B11obFhrSxRo"
      },
      "outputs": [],
      "source": [
        "valid_split = 0.1\n",
        "\n",
        "shuffle_seed = 43\n",
        "\n",
        "sample_rate = 16000\n",
        "\n",
        "scale = 0.5\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYjZsxLodJe8"
      },
      "source": [
        "Arrange audio and noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCMGoGzyS_h5"
      },
      "outputs": [],
      "source": [
        "for folder in os.listdir(data_directory):\n",
        "    if os.path.isdir(os.path.join(data_directory, folder)):\n",
        "        if folder in [audio_folder, noise_folder]:\n",
        "\n",
        "            continue\n",
        "        elif folder in [\"_background_noise_\"]:\n",
        "\n",
        "            shutil.move(\n",
        "                os.path.join(data_directory, folder),\n",
        "                os.path.join(noise_path, folder),\n",
        "            )\n",
        "        else:\n",
        "            shutil.move(\n",
        "                os.path.join(data_directory, folder),\n",
        "                os.path.join(audio_path, folder),\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAuKGfQTTE2-"
      },
      "outputs": [],
      "source": [
        "noise_paths = []\n",
        "for subdir in os.listdir(noise_path):\n",
        "    subdir_path = Path(noise_path) / subdir\n",
        "    if os.path.isdir(subdir_path):\n",
        "        noise_paths += [\n",
        "            os.path.join(subdir_path, filepath)\n",
        "            for filepath in os.listdir(subdir_path)\n",
        "            if filepath.endswith(\".wav\")\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtOEH_mGTZHB",
        "outputId": "aaa7e88e-8f85-4cb4-f58c-044f4414b011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deepfake_dataset/AUDIO/noise/_background_noise_/running_tap.wav',\n",
              " 'deepfake_dataset/AUDIO/noise/_background_noise_/dude_miaowing.wav',\n",
              " 'deepfake_dataset/AUDIO/noise/_background_noise_/10convert.com_Audience-Claps_daSG5fwdA7o.wav',\n",
              " 'deepfake_dataset/AUDIO/noise/_background_noise_/doing_the_dishes.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "noise_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75T_mQaSTcpn"
      },
      "outputs": [],
      "source": [
        "command = (\n",
        "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
        "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
        "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
        "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
        "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
        "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
        "    \"-i $file -ar 16000 temp.wav; \"\n",
        "    \"mv temp.wav $file; \"\n",
        "    \"fi; done; done\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eINSBB-Em-rQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.system(command)\n",
        "def load_noise_sample(path):\n",
        "    sample, sampling_rate = tf.audio.decode_wav(\n",
        "        tf.io.read_file(path), desired_channels=1\n",
        "    )\n",
        "    if sampling_rate == sample_rate:\n",
        "        slices = int(sample.shape[0] / sample_rate)\n",
        "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
        "        return sample\n",
        "    else:\n",
        "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
        "        return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQTrV0cdTu-"
      },
      "source": [
        "Selecting portion of dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3h0g0nXm0Zw"
      },
      "outputs": [],
      "source": [
        "noises = []\n",
        "for path in noise_paths:\n",
        "    sample = load_noise_sample(path)\n",
        "    if sample:\n",
        "        noises.extend(sample)\n",
        "noises = tf.stack(noises)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKkh4EfMTvWX"
      },
      "source": [
        "Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeNSX1WUtZpi"
      },
      "outputs": [],
      "source": [
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(\n",
        "        lambda x: path_to_audio(x), num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n",
        "    return audio\n"
      ],
      "metadata": {
        "id": "Po9Ketv-0G2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPAC18ZjT2-4"
      },
      "source": [
        "Noise Addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IirpBvIBTsu4"
      },
      "outputs": [],
      "source": [
        "def add_noise(audio, noises=None, scale=0.5):\n",
        "    if noises is not None:\n",
        "        tf_rnd = tf.random.uniform(\n",
        "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
        "        )\n",
        "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
        "\n",
        "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
        "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
        "\n",
        "        audio = audio + noise * prop * scale\n",
        "\n",
        "    return audio\n",
        "\n",
        "def audio_to_fft(audio):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    fft = tf.signal.fft(\n",
        "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    )\n",
        "    fft = tf.expand_dims(fft, axis=-1)\n",
        "\n",
        "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P-YAkXRT_Ss",
        "outputId": "995f5d6d-cf91-4145-e3cf-e59babafd217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['FAKE', 'REAL']\n"
          ]
        }
      ],
      "source": [
        "class_names = os.listdir(audio_path)\n",
        "print(class_names,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0kqYZad7vyk",
        "outputId": "6a2c5567-cee2-49a2-d521-7c1682064667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification: FAKE\n",
            "Classification: REAL\n",
            "Found 478 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "audio_paths = []\n",
        "labels = []\n",
        "\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"Classification:\",(name))\n",
        "    dir_path = Path(audio_path) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)\n",
        "\n",
        "print(\"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPfwu3oyUA_o"
      },
      "outputs": [],
      "source": [
        "# Shuffle to generate random data\n",
        "rng = np.random.RandomState(shuffle_seed)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(shuffle_seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "num_val_samples = int(valid_split * len(audio_paths))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]\n",
        "\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(batch_size)\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrRk6uR-UHO4"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1OQTdkVUOnB"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        ")\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "\n",
        "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoVxoy4LUVhL"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpCwyeztUXpe",
        "outputId": "992b72ed-0030-4e98-c9c5-52e7282fde47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input (InputLayer)          [(None, 8000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_69 (Conv1D)          (None, 8000, 128)            512       ['input[0][0]']               \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 8000, 128)            0         ['conv1d_69[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_70 (Conv1D)          (None, 8000, 128)            49280     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 8000, 128)            0         ['conv1d_70[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_71 (Conv1D)          (None, 8000, 128)            49280     ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_68 (Conv1D)          (None, 8000, 128)            256       ['input[0][0]']               \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 8000, 128)            0         ['conv1d_71[0][0]',           \n",
            "                                                                     'conv1d_68[0][0]']           \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 8000, 128)            0         ['add_19[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_19 (MaxPooli  (None, 4000, 128)            0         ['activation_51[0][0]']       \n",
            " ng1D)                                                                                            \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (Avera  (None, 1333, 128)            0         ['max_pooling1d_19[0][0]']    \n",
            " gePooling1D)                                                                                     \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 170624)               0         ['average_pooling1d_3[0][0]'] \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  4368000   ['flatten_3[0][0]']           \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  32896     ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 2)                    258       ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43812482 (167.13 MB)\n",
            "Trainable params: 43812482 (167.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv1D\n",
        "def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n",
        "    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n",
        "\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "\n",
        "    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "\n",
        "    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(inputs, 32, 2)\n",
        "    x = residual_block(inputs, 64, 3)\n",
        "    x = residual_block(inputs, 128, 3)\n",
        "    x = residual_block(inputs, 128, 3)\n",
        "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "model = build_model((sample_rate // 2, 1), len(class_names))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model_save_filename = \"model.h5\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66vk45kldoEL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8orMgAfUfbY",
        "outputId": "2cf19b85-fcd3-4aed-e891-d211f390508d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - ETA: 0s - loss: 17.0100 - accuracy: 0.5290 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 87s 11s/step - loss: 17.0100 - accuracy: 0.5290 - val_loss: 1.6300 - val_accuracy: 0.5106\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 78s 10s/step - loss: 1.4210 - accuracy: 0.6102 - val_loss: 0.6308 - val_accuracy: 0.7021\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 68s 9s/step - loss: 0.6563 - accuracy: 0.6125 - val_loss: 0.6651 - val_accuracy: 0.4681\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 68s 9s/step - loss: 0.6150 - accuracy: 0.6682 - val_loss: 0.6410 - val_accuracy: 0.5957\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 71s 9s/step - loss: 0.5487 - accuracy: 0.7517 - val_loss: 0.5759 - val_accuracy: 0.7021\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 70s 9s/step - loss: 0.4821 - accuracy: 0.7889 - val_loss: 0.5728 - val_accuracy: 0.7021\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 73s 10s/step - loss: 0.4323 - accuracy: 0.8167 - val_loss: 0.4346 - val_accuracy: 0.8298\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 76s 10s/step - loss: 0.4040 - accuracy: 0.8121 - val_loss: 0.4068 - val_accuracy: 0.7872\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 69s 9s/step - loss: 0.3504 - accuracy: 0.8329 - val_loss: 0.5246 - val_accuracy: 0.7447\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 70s 9s/step - loss: 0.2663 - accuracy: 0.8863 - val_loss: 0.4195 - val_accuracy: 0.8298\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJpmjC7udqyU"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNL5PY3BFH3M",
        "outputId": "eeec7aff-6eeb-4958-e0cd-e2580107b208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 4s 567ms/step - loss: 0.4195 - accuracy: 0.8298\n",
            "Accuracy of model: [0.41954582929611206, 0.8297872543334961]\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of model:\",model.evaluate(valid_ds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/model.h5')"
      ],
      "metadata": {
        "id": "a4cB8Wau2s26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16979f2-c777-455f-c030-dfb0d114e35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLES_TO_DISPLAY = 10\n",
        "\n",
        "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "test_ds = test_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(batch_size)\n",
        "\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y),num_parallel_calls=tf.data.AUTOTUNE,)\n",
        "\n",
        "for audios, labels in test_ds.take(1):\n",
        "    ffts = audio_to_fft(audios)\n",
        "    y_pred = model.predict(ffts)\n",
        "    dataset_size = len(valid_audio_paths)\n",
        "    #rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n",
        "    rnd = np.random.randint(0, dataset_size, min(SAMPLES_TO_DISPLAY, dataset_size))\n",
        "    audios = audios.numpy()[rnd, :, :]\n",
        "    labels = labels.numpy()[rnd]\n",
        "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(SAMPLES_TO_DISPLAY):\n",
        "        print(\n",
        "            \"Audio:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[labels[index]],\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[y_pred[index]],\n",
        "            )\n",
        "        )\n",
        "        if labels[index] ==y_pred[index]:\n",
        "            print(\"Welcome\")\n",
        "        else:\n",
        "            print(\"Sorry\")\n",
        "        print(\"The audio is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRRA-6FFbSyY",
        "outputId": "6200ba9d-d7af-442a-9ef2-8834d086210c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 549ms/step\n",
            "Audio:\u001b[92m REAL\u001b[0m\tPredicted:\u001b[92m REAL\u001b[0m\n",
            "Welcome\n",
            "The audio is REAL\n",
            "Audio:\u001b[92m REAL\u001b[0m\tPredicted:\u001b[92m REAL\u001b[0m\n",
            "Welcome\n",
            "The audio is REAL\n",
            "Audio:\u001b[92m FAKE\u001b[0m\tPredicted:\u001b[92m FAKE\u001b[0m\n",
            "Welcome\n",
            "The audio is FAKE\n",
            "Audio:\u001b[92m FAKE\u001b[0m\tPredicted:\u001b[92m FAKE\u001b[0m\n",
            "Welcome\n",
            "The audio is FAKE\n",
            "Audio:\u001b[92m REAL\u001b[0m\tPredicted:\u001b[92m REAL\u001b[0m\n",
            "Welcome\n",
            "The audio is REAL\n",
            "Audio:\u001b[92m FAKE\u001b[0m\tPredicted:\u001b[92m FAKE\u001b[0m\n",
            "Welcome\n",
            "The audio is FAKE\n",
            "Audio:\u001b[92m REAL\u001b[0m\tPredicted:\u001b[92m REAL\u001b[0m\n",
            "Welcome\n",
            "The audio is REAL\n",
            "Audio:\u001b[92m REAL\u001b[0m\tPredicted:\u001b[92m REAL\u001b[0m\n",
            "Welcome\n",
            "The audio is REAL\n",
            "Audio:\u001b[92m REAL\u001b[0m\tPredicted:\u001b[92m REAL\u001b[0m\n",
            "Welcome\n",
            "The audio is REAL\n",
            "Audio:\u001b[92m FAKE\u001b[0m\tPredicted:\u001b[92m FAKE\u001b[0m\n",
            "Welcome\n",
            "The audio is FAKE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def paths_to_dataset(audio_paths):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    return tf.data.Dataset.zip((path_ds))\n",
        "\n",
        "def predict(path, labels):\n",
        "    test = paths_and_labels_to_dataset(path, labels)\n",
        "\n",
        "\n",
        "    test = test.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
        "    batch_size\n",
        "    )\n",
        "    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "    test = test.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
        "\n",
        "    for audios, labels in test.take(1):\n",
        "        ffts = audio_to_fft(audios)\n",
        "        y_pred = model.predict(ffts)\n",
        "        rnd = np.random.randint(0, 1, 1)\n",
        "        audios = audios.numpy()[rnd, :]\n",
        "        labels = labels.numpy()[rnd]\n",
        "        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(1):\n",
        "            print(\n",
        "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "            \"[92m\",y_pred[index],\n",
        "                \"[92m\", y_pred[index]\n",
        "                )\n",
        "            )\n",
        "\n",
        "            print(\"Speaker Predicted:\",class_names[y_pred[index]])\n",
        "path = [\"../content/gdrive/MyDrive/murf.wav\"]\n",
        "labels = [\"unknown\"]\n",
        "try:\n",
        "    predict(path, labels)\n",
        "except:\n",
        "    print(\"Error! Check if the file correctly passed or not!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwMDp6LHzDl2",
        "outputId": "c0a33a07-e6b0-4dc5-ce65-ae37e2b744c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 230ms/step\n",
            "Speaker:\u001b[92m 0\u001b[0m\tPredicted:\u001b[92m 0\u001b[0m\n",
            "Speaker Predicted: FAKE\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}